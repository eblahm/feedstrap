{"ts":1366116481157,"silentsave":true,"restoring":false,"patch":[[{"diffs":[[1,"import os\nimport urllib2\nimport pytz\nfrom time import mktime\nfrom datetime import datetime\nimport xml.etree.ElementTree as etree\nfrom ssg_site import feedparser, AlchemyAPI\nfrom feedstrap import models\nfrom django.core.management.base import BaseCommand, CommandError\n\nclass Command(BaseCommand):\n    def handle(self, *args, **kwargs):\n        ## Query fetches in ascending order according to when feeds were last updated\n        feeds_query = models.Feed.objects.all().order_by('last_updated')\n        for feed in feeds_query:\n            self.stdout.write('fetching \"%s\"' % feed.name)\n            parsed_feed = feedparser.parse(feed.url)\n            # query for latest database item according to this particular feed\n            ## The latest item in the RSS feed is compared with latest item in the database to determine\n            ## weather or not a new item is present, further processing will happen to determine if the links are actually new\n            try:\n                most_recent_from_db = models.Resource.objects.filter(feeds__pk=feed.pk).order_by(\"-date\")[0].date\n            except:\n                most_recent_from_db = datetime(1901, 12, 25)\n            most_recent_from_db = most_recent_from_db.replace(tzinfo=pytz.utc)\n\n            most_recent_from_feed = datetime.fromtimestamp(mktime(parsed_feed.entries[0].published_parsed))\n            most_recent_from_feed = most_recent_from_feed.replace(tzinfo=pytz.utc)\n\n            if most_recent_from_db < most_recent_from_feed:\n                ## new items should now be present\n                for item in parsed_feed.entries:\n                    found = 0\n                    ## if a user has deleted the item it goes on the \"Deleted\" list.  These should be ignored.\n                    if models.DeletedLink.objects.filter(link=item.link).count() > 0:\n                        continue\n                        ## check membership in Resource Table\n                    membership_query = models.Resource.objects.all().filter(link=item.link)\n                    feed_limited_query = membership_query.filter(feeds__pk=feed.pk)\n                    if feed_limited_query.count() > 0:\n                        found += 1\n                        if found > 4:\n                            # minimize db queries\n                            break\n                    else:\n                        if membership_query.count() == 0:\n                            dt = datetime.fromtimestamp(mktime(item.published_parsed))\n                            dt = dt.replace(tzinfo=pytz.utc)\n                            r = models.Resource(title=item.title,\n                                                link=item.link,\n                                                date=dt,\n                                                description=item.description)\n                            r.save()\n                            r.feeds.add(feed)\n                            try:\n                                page = urllib2.urlopen(item.link)\n                                page_content = page.read()\n                                alchemyObj = AlchemyAPI.AlchemyAPI()\n                                alchemyObj.loadAPIKey(\"/Users/Matt/Dropbox/dev/ssg_site/ssg_site/alcAPI.txt\")\n                                article_xml = alchemyObj.HTMLGetText(page_content, item.link)\n                                text = etree.fromstring(article_xml).find(\"text\").text.encode('utf-8','ignore')\n                                r.content = text\n                            except:\n                                pass\n                            r.save()\n                        else:\n                            r = membership_query.get()\n                        if feed not in r.feeds.all():\n                            r.feeds.add(feed)\n                        for tag in feed.tags.all():\n                            if tag not in r.tags.all():\n                                r.tags.add(tag)\n                        for office in feed.offices.all():\n                            if office not in r.offices.all():\n                                r.offices.add(office)\n                        for report in feed.reports.all():\n                            if report not in r.reports.all():\n                                r.reports.add(report)\n                        for topic in feed.topics.all():\n                            if topic not in r.topics.all():\n                                r.topics.add(topic)\n                        r.save()\n                        self.stdout.write('New Resource Added! -- \"%s\"' % r.title)\n                #CommandError('Poll \"%s\" does not exist' % poll_id)\n\n\n"]],"start1":0,"start2":0,"length1":0,"length2":4630}]],"length":4630}
{"contributors":[],"silentsave":true,"ts":1366287742288,"patch":[[{"diffs":[[0,"y(\"/"],[-1,"Users/Matt/Dropbox/dev/ssg_site/"],[0,"ssg_"]],"start1":3164,"start2":3164,"length1":40,"length2":8}]],"length":4598,"saved":false}
{"ts":1366287771952,"patch":[[{"diffs":[[0,"PIKey(\"/"],[1,"Users/Matt/Dropbox/dev/ssg_site/"],[0,"ssg_site"]],"start1":3160,"start2":3160,"length1":16,"length2":48}]],"length":4630,"saved":false}
